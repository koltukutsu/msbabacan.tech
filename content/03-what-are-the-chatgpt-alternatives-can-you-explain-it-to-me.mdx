---
title: "What are the ChatGPT Alternatives?"
summary: "ChatGPT, a popular AI language model that uses the GPT-3.5 architecture with RLHF for chat systems, and is considered one of the most advanced language models in the world. While ChatGPT is powerful, there are other options available. This article explores some of the best open-source, free alternatives to ChatGPT for chat systems."
category: "Artificial Intelligence"
publishedAt: "2023-03-27"
image: "/images/03/chatgpt-alternatives.png"
coverImage: "/images/03/chatgpt-alternatives.png"
coverImageBlur: "/images/03/chatgpt-alternatives-blur.png"
coverImageAlt: "What are the ChatGPT Alternatives?"
---

# What are the ChatGPT Alternatives?

ChatGPT is a popular AI language model that has revolutionized the way humans interact with machines. It uses the GPT-3.5 architecture with RLHF (Reinforcement Learning with Human Feedback) for chat systems, and it's currently considered one of the most advanced language models in the world.

However, while ChatGPT is incredibly powerful, it's not the only option available. In this article, we will explore some of the best alternatives to ChatGPT that are currently available on the market. These projects feature different language models for chat systems, and they are open-source, free, and available for anyone to use.

**Note:** Projects that are not counted in this list are alternative frontend projects because they just call the API from OpenAI and alternative transformer decoder models to GPT 3.5 either because the training data of them are (mostly) not for the chat system.

**The following tags will be used:**

- **Bare** (no data, no model's weight, no chat system)
- **Mildly Bare** (yes data, yes model's weight, bare chat via API)
- **Full** (yes data, yes model's weight, fancy chat system including TUI and GUI)
- **Complicated** (semi open source, not really open source, based on a closed model, ...)

## **[lucidrains/PaLM-rlhf-pytorch](https://github.com/lucidrains/PaLM-rlhf-pytorch)**

PaLM-rlhf-pytorch is an implementation of RLHF on top of the PaLM architecture. Essentially, this is a version of ChatGPT that uses the PaLM language model instead of the GPT-3.5 architecture. PaLM stands for Parameter-efficient Language Model, and it's designed to be smaller and faster than other language models. This implementation is great for those who want a bare-bones version of ChatGPT.

**Tags: Bare**

## **[togethercomputer/OpenChatKit](https://github.com/togethercomputer/OpenChatKit)**

OpenChatKit is a powerful, open-source base that you can use to create both specialized and general-purpose chatbots for various applications. It uses a pre-trained language model that can understand natural language input and provide natural language output. OpenChatKit is designed to be flexible, so you can customize it to your needs. It also features a full chat system that includes a TUI and GUI, making it easy to use for both developers and non-developers.

**Tags: Full**

## **[oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui)**

This is a gradio web UI for running large language models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion. It allows you to generate text using these models in a simple and user-friendly way. The web UI is open-source, free to use, and can be run locally on your machine. You can choose between several pre-trained models and fine-tune them to generate text that meets your specific needs.

**Tags: Full**

## **[KoboldAI/KoboldAI-Client](https://github.com/KoboldAI/KoboldAI-Client)**

KoboldAI-Client is a browser-based front-end for AI-assisted writing with multiple local and remote AI models. It offers the standard array of tools, including Memory, Author’s Note, World Info, Save and Load, adjustable AI settings, formatting options, and the ability to import existing AI Dungeon adventures. You can also turn on Adventure mode and play the game like AI Dungeon Unleashed. KoboldAI-Client is open-source, free, and available for anyone to use.

ChatGPT is a popular AI language model that has revolutionized the way humans interact with machines. It uses the GPT-3.5 architecture with RLHF (Reinforcement Learning with Human Feedback) for chat systems, and it's currently considered one of the most advanced language models in the world.

However, while ChatGPT is incredibly powerful, it's not the only option available. In this article, we will explore some of the best alternatives to ChatGPT that are currently available on the market. These projects feature different language models for chat systems, and they are open-source, free, and available for anyone to use.

## **[LAION-AI/Open-Assistant](https://github.com/LAION-AI/Open-Assistant)**

OpenAssistant is a chat-based assistant that simplifies your daily tasks. It can interact with third-party systems and retrieve information dynamically, making it a one-of-a-kind tool. With OpenAssistant, you can schedule appointments, send emails, order groceries, and more. Try it out today and see how it can transform the way you work and live. Visit **[LAION-AI/Open-Assistant](https://github.com/LAION-AI/Open-Assistant)** to learn more and get started.

Related links:

- **[huggingface.co/OpenAssistant](https://huggingface.co/OpenAssistant)**
- **[r/OpenAssistant/](https://www.reddit.com/r/OpenAssistant/)**

**Tags: F**

## **[tatsu-lab/stanford_alpaca](https://github.com/tatsu-lab/stanford_alpaca)**

This repository contains the Stanford Alpaca project, which aims to build and share an instruction-following LLaMA model. The LLaMA model is an advanced language model that can understand and follow instructions. It is specifically designed for instruction-based tasks, such as cooking recipes, assembly instructions, and more. The Stanford Alpaca project is a great option for anyone looking for a powerful, open-source, and free instruction-following language model.

Related links:

- **[pointnetwork/point-alpaca](https://github.com/pointnetwork/point-alpaca)**
- **[tloen/alpaca-lora](https://github.com/tloen/alpaca-lora)**
- **[r/LocalLLaMA How to install LLaMA: 8-bit and 4-bit](https://www.reddit.com/r/LocalLLaMA/comments/11o6o3f/how_to_install_llama_8bit_and_4bit/)**
- **[antimatter15/alpaca.cpp](https://github.com/antimatter15/alpaca.cpp)**
- **[ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)**
- **[setzer22/llama-rs](https://github.com/setzer22/llama-rs)**

See these Reddit comments first **[#1](https://www.reddit.com/r/MachineLearning/comments/11uk8ti/comment/jcpd3yu/?utm_source=share&utm_medium=web2x&context=3)**

**Tags: Complicated**

## **[BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)**

ChatRWKV is an open-source project developed by BlinkDL, a team of passionate developers who aim to create cutting-edge technology that can enhance human communication and interaction. Unlike ChatGPT, which is based on the GPT-3.5 architecture, ChatRWKV is powered by RWKV, a 100% RNN language model.

ChatRWKV is an open-source project developed by BlinkDL, a team of passionate developers who aim to create cutting-edge technology that can enhance human communication and interaction. Unlike ChatGPT, which is based on the GPT-3.5 architecture, ChatRWKV is powered by RWKV, a 100% RNN language model.

ChatRWKV is designed to provide users with a more personalized and natural conversation experience. The model is trained on a diverse range of datasets and has the ability to generate responses that are contextually relevant and linguistically sound. The RWKV model is capable of understanding complex sentence structures and can generate meaningful responses that are tailored to the user's specific needs.

One of the main advantages of using ChatRWKV is its ability to handle a wide range of conversations, from simple small talk to complex technical discussions. The model can be trained on specific topics or domains, allowing it to generate responses that are more relevant and accurate. This makes ChatRWKV a useful tool for a variety of applications, including customer service, chatbots, and virtual assistants.

**Tags: Full**

## **[THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)**

ChatGLM-6B is an open bilingual language model based on the General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).

**Tags: Full**

## [bigscience-workshop/xmtf](https://github.com/bigscience-workshop/xmtf)

This repository provides an overview of all components used for the creation of BLOOMZ & mT0 and xP3 introduced in the paper [Crosslingual Generalization through Multitask Finetuning](https://arxiv.org/abs/2211.01786).

Related links:

- [bigscience/bloomz](https://huggingface.co/bigscience/bloomz)
- [bigscience/mt0-base](https://huggingface.co/bigscience/mt0-base)

Tags: Standard

## [carperai/trlx](https://github.com/carperai/trlx)

A repo for distributed training of language models with Reinforcement Learning via Human Feedback (RLHF), supporting online RL up to 20b params and offline RL to larger models. Basically what you would use to finetune GPT into ChatGPT.

Tags: Bare

## [databrickslabs/dolly](https://github.com/databrickslabs/dolly)

Script to fine tune [GPT-J 6B](https://huggingface.co/EleutherAI/gpt-j-6B) model on the [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) dataset. Insightful if you want to fine tune LLMs.

Related links:

- [6b model card](https://huggingface.co/databricks/dolly-v1-6b)

Tags: Standard

## [LianjiaTech/BELLE](https://github.com/LianjiaTech/BELLE)

The goal of this project is to promote the development of the open-source community for Chinese language large-scale conversational models. This project optimizes Chinese performance in addition to original Stanford Alpaca. The model finetuning uses only data generated via ChatGPT (without other data). This repo contains: 175 chinese seed tasks used for generating the data, code for generating the data, 0.5M generated data used for fine-tuning the model, model finetuned from BLOOMZ-7B1-mt on data generated by this project.

Related links:

- [English readme](https://github.com/LianjiaTech/BELLE#-belle-be-large-language-model-engine-1)

Tags: Standard

## [ethanyanjiali/minChatGPT](https://github.com/ethanyanjiali/minChatGPT)

A minimum example of aligning language models with RLHF similar to ChatGPT

Related links:

- [huggingface.co/ethanyanjiali/minChatGPT](https://huggingface.co/ethanyanjiali/minChatGPT)

Tags: Standard

## [cerebras/Cerebras-GPT](https://huggingface.co/cerebras/Cerebras-GPT-6.7B)

7 open source GPT-3 style models with parameter ranges from 111 million to 13 billion, trained using the [Chinchilla](https://arxiv.org/abs/2203.15556) formula. Model weights have been released under a permissive license (Apache 2.0 license in particular).

Related links:

- [Announcement](https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/)
- [Models with other amount of parameters](https://huggingface.co/cerebras)

Tags: Standard

## [TavernAI/TavernAI](https://github.com/TavernAI/TavernAI)

Atmospheric adventure chat for AI language model **Pygmalion** by default and other models such as **KoboldAI**, ChatGPT, GPT-4

Tags: Full
